You are Replit. Operate as a senior full-stack engineer + architect. 
Hard rules:
- NO mock/demo/hardcoded “successful” states. Every UI status must be backed by real DB state and/or Alpaca source-of-truth.
- Do not claim a task is “done” unless you provide proof: file diffs + runtime proof (curl output, UI screenshot, or logs).
- Prefer enriching existing modules/pages (admin is WordPress-like and already exists). Do NOT create duplicates.
- Before changing anything: run ripgrep to locate existing files/components and list what you found.

GOAL (P0): Fix the Order Lifecycle + UI Truth Problem
Your audit shows G4: only trades table exists; orders/fills lifecycle is conflated, causing confusing statuses in UI. Fix this by implementing a real Order→Fill lifecycle (minimal new tables + Alpaca trade_updates listener), then wire the UI + existing Admin dashboard to monitor and control it.

PHASE 1 — Read docs + confirm reality (no assumptions)
1) Read these docs first and summarize the “must match reality” contract in 10 bullets:
   - docs/SOURCE_OF_TRUTH_CONTRACT.md
   - docs/TRADING_SAGA_SEQUENCES.md
   - docs/OBSERVABILITY.md
   - docs/AI_MODELS_AND_PROVIDERS.md
   - AUDIT_DOC_VS_IMPLEMENTATION_GAP.md (uploaded)
2) Inspect current DB schema in shared/schema.ts:
   - Confirm what tables exist for trades, ai_decisions, llm_calls, work_items, etc.
   - Confirm there is no orders/fills table (per audit) and identify where brokerOrderId is stored today (work_items payload/result, trades, etc).
3) Inspect server order execution path end-to-end:
   - Find where ORDER_SUBMIT work item is created (orchestrator) and processed (work queue worker).
   - Confirm enforcement gate integration (universe tradingEnforcement) is enforced BEFORE order submission.

PHASE 2 — Implement a minimal, real Order + Fill data model (close G4)
4) Add new tables (Drizzle in shared/schema.ts) WITHOUT breaking current trades table:
   A) broker_orders
      - id (uuid)
      - traceId (text, indexed)
      - decisionId (nullable, fk if exists)
      - symbol, side, qty, orderType, timeInForce
      - status (enum: created|submitted|accepted|partially_filled|filled|canceled|rejected|expired)
      - broker (default 'alpaca')
      - brokerOrderId (text, unique, nullable until submit returns)
      - submittedAt, updatedAt, filledAt
      - filledQty, avgFillPrice (numeric)
      - rawLastEvent (jsonb)
   B) broker_fills
      - id (uuid)
      - brokerOrderId (text, indexed)
      - traceId (text, indexed)
      - symbol, qty, price, liquidity (nullable)
      - occurredAt
      - raw (jsonb)
   C) broker_order_events (optional but recommended)
      - id, brokerOrderId, traceId, eventType, occurredAt, raw(jsonb)

5) Migration: run npm run db:push and show output.

6) Wire work queue ORDER_SUBMIT handler:
   - When enqueuing ORDER_SUBMIT, create broker_orders row first with status='created' and traceId.
   - When Alpaca submit order returns brokerOrderId, update broker_orders with brokerOrderId + status='submitted' and link to trades/decision if applicable.
   - Ensure idempotency: if the same idempotencyKey replays, do NOT create duplicate broker_orders; reuse existing row (by idempotencyKey mapping or by (traceId,symbol,side,time-bucket) deterministic key).
   - For ORDER_CANCEL: update broker_orders status='canceled' only when confirmed by Alpaca update events (or at least mark ‘cancel_requested’ if you add it).

PHASE 3 — Alpaca trade_updates streaming listener (source-of-truth lifecycle)
7) Implement an Alpaca trade_updates listener service (server/brokers/alpacaTradeUpdates.ts):
   - Connect to Alpaca WebSocket stream:
     - paper: wss://paper-api.alpaca.markets/stream
     - live:  wss://api.alpaca.markets/stream
   - Authenticate and subscribe to trade_updates (per Alpaca WebSocket streaming docs).
   - On each incoming update:
     - Map Alpaca event to broker_orders.status (accepted/filled/partial_fill/canceled/rejected/etc).
     - Persist raw event to broker_order_events and rawLastEvent in broker_orders.
     - If fill/partial_fill: insert broker_fills rows and roll up filledQty + avgFillPrice.
   - Add robust reconnect with exponential backoff; log traceId if present, else derive traceId by looking up broker_orders via brokerOrderId.
   - Add a feature flag env var ENABLE_ALPACA_TRADE_UPDATES=true and start listener on server bootstrap (similar to work queue worker startup).

PHASE 4 — Make the UI truthful (no more “pending_execution” nonsense)
8) Fix “Trade Ledger” and “AI Suggested Trades” screens:
   - Replace any UI status computed from internal mock fields with broker_orders.status + Alpaca positions/orders endpoints if needed.
   - Add a single canonical “Order Status” component that renders:
     - status badge
     - last update time
     - filledQty / qty + avgFillPrice
     - failure reason if rejected (from raw event)
     - traceId link (drilldown)
   - Ensure every row shown in ledger maps to either:
     - a broker_orders row OR
     - a real Alpaca position (if it’s a position view)
     - Never show unattached “trades” that can’t be reconciled.

9) Add “Order Drilldown” page:
   - /admin/orders/:brokerOrderId (admin-only) and optionally /orders/:brokerOrderId (user view)
   - Show: broker order timeline (events), linked AI decision, linked LLM calls (by traceId), and resulting position impact.

PHASE 5 — Consolidate Admin into ONE WordPress-like Admin Hub + entry point
10) Admin UX requirements:
   - There is already a WordPress-inspired Admin page; FIND it and extend it. Do NOT duplicate.
   - Create a dedicated entry point:
     - Route: /admin
     - Add a clear link in the main nav only for admins.
     - Add an access note in docs: how to login as admin and reach /admin.

11) Consolidate all admin-related pages into the single Admin hub with sidebar sections:
   A) System Overview (health, last orchestrator cycle, last errors)
   B) Work Queue (pending/running/dead-letter + retry button)
   C) Orders (broker_orders table, filters by status, drilldown)
   D) Universe (fundamentals, candidates approval, enforcement stats)
   E) Allocation Policies + Rebalancer controls
   F) Connectors & API Budgets (OpenAI/OpenRouter/Valyu/Finnhub/etc) — show budget + cache hit rate; NO duplication if already present
   G) Observability (traceId search: show ai_decisions + llm_calls + trades + broker_orders + events)

12) Every admin button must have real effect + visible result:
   - “Start Alpaca trade_updates listener” (if disabled)
   - “Test submit order” (paper only) -> creates broker_order -> receives updates -> UI shows filled
   - “Replay traceId” -> shows full chain of records

PHASE 6 — Validation (prove it works)
13) Provide proof with:
   - curl scripts (login, submit a paper order, fetch broker_orders status until filled)
   - server logs showing trade_updates received and persisted
   - UI screenshot or description of the exact page showing the order lifecycle correctly
14) Add at least 2 integration tests:
   - Work queue ORDER_SUBMIT creates broker_orders and updates brokerOrderId
   - trade_updates handler updates broker_orders.status and inserts broker_fills

PHASE 7 — Docs update (mandatory)
15) Update docs to reflect reality:
   - docs/SOURCE_OF_TRUTH_CONTRACT.md: include broker_orders/broker_fills and what the UI must display
   - docs/TRADING_SAGA_SEQUENCES.md: add “current monolith saga” section vs future NATS section
   - docs/OBSERVABILITY.md: how traceId links across ai_decisions, llm_calls, broker_orders, fills

Deliverables:
- List of files changed + why
- Commands run + outputs
- The UI pages/paths to verify (/admin, /admin/orders, etc)
- What remains for the next phase
