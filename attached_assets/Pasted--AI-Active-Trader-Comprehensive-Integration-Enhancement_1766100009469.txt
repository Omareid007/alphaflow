# AI Active Trader - Comprehensive Integration Enhancement Prompt

> **REPLIT AGENT INSTRUCTION SET**
> Execute this prompt to integrate free/open-source data sources, social media listeners, ML models, and rate-limited fallback architecture into the AI Active Trader platform.

---

## PROJECT CONTEXT

### Existing Architecture
- **Runtime**: Node.js 20+ / TypeScript on Replit Reserved VM (8GB RAM, 2 vCPU)
- **Backend**: Express.js microservices architecture (ports 3000-3005)
- **Database**: PostgreSQL (Neon) with Drizzle ORM
- **Frontend**: React Native/Expo (mobile + web)
- **Event Bus**: NATS JetStream
- **Current Integrations**: Alpaca (broker), Finnhub, CoinGecko, NewsAPI, CoinMarketCap, GDELT, Hugging Face FinBERT, OpenAI/Groq/Together.ai LLMs

### Goal
Integrate **17+ free/open-source data sources** with multi-provider fallback, rate limiting, circuit breakers, and unified caching to:
1. Reduce API costs by 60-80%
2. Increase data reliability through redundancy
3. Add social sentiment signals (Reddit, StockTwits)
4. Enable ML-powered forecasting and enhanced sentiment analysis

---

## PHASE 1: CORE INFRASTRUCTURE

### 1.1 Install Dependencies

```bash
# Rate limiting and resilience
npm install bottleneck opossum p-limit

# Data source clients
npm install @fredapi/fred-api python-shell cheerio
npm install ccxt  # Unified crypto exchange API

# Social media
npm install snoowrap  # Reddit API

# ML/Sentiment (if running local inference)
npm install @xenova/transformers  # Browser/Node transformer models

# Utilities
npm install lru-cache node-cache reconnecting-websocket
npm install zod  # Already installed, for schema validation
```

### 1.2 Create Rate Limiter Service

**File: `server/lib/rateLimiter.ts`**

```typescript
import Bottleneck from 'bottleneck';

export interface ProviderLimits {
  maxPerSecond?: number;
  maxPerMinute?: number;
  maxPerHour?: number;
  maxPerDay?: number;
  maxConcurrent?: number;
  minTime?: number; // ms between requests
}

const PROVIDER_LIMITS: Record<string, ProviderLimits> = {
  // Stock Data
  'sec-edgar': { maxPerSecond: 10, maxConcurrent: 5 },
  'alpha-vantage': { maxPerDay: 25, maxPerMinute: 5, maxConcurrent: 1, minTime: 12000 },
  'yfinance': { maxPerHour: 2000, maxPerMinute: 60, maxConcurrent: 3 },
  'polygon-free': { maxPerMinute: 5, maxConcurrent: 1, minTime: 12000 },
  
  // Crypto Data
  'binance': { maxPerMinute: 1200, maxConcurrent: 10 }, // 6000 weight/min, ~5 weight per call
  'defillama': { maxPerMinute: 60, maxConcurrent: 5 },
  'cryptocompare': { maxPerSecond: 50, maxPerDay: 200000, maxConcurrent: 10 },
  
  // Economic Data
  'fred': { maxPerMinute: 120, maxConcurrent: 5 },
  
  // Social Media
  'reddit': { maxPerMinute: 100, maxConcurrent: 2 },
  'stocktwits': { maxPerMinute: 200, maxConcurrent: 3 },
  
  // News/Scraping
  'yahoo-scrape': { maxPerMinute: 60, maxConcurrent: 2, minTime: 1000 },
  
  // ML Inference
  'huggingface-inference': { maxPerMinute: 30, maxConcurrent: 2 },
  
  // Existing (keep current limits)
  'finnhub': { maxPerMinute: 50, maxConcurrent: 3 },
  'coingecko': { maxPerMinute: 10, maxPerDay: 500, maxConcurrent: 2 },
  'newsapi': { maxPerDay: 80, maxConcurrent: 1 },
};

const limiters: Map<string, Bottleneck> = new Map();

export function getLimiter(provider: string): Bottleneck {
  if (limiters.has(provider)) {
    return limiters.get(provider)!;
  }

  const limits = PROVIDER_LIMITS[provider] || { maxPerMinute: 60 };
  
  const limiter = new Bottleneck({
    maxConcurrent: limits.maxConcurrent || 5,
    minTime: limits.minTime || 0,
    reservoir: limits.maxPerMinute || limits.maxPerSecond ? (limits.maxPerSecond || 0) * 60 + (limits.maxPerMinute || 0) : undefined,
    reservoirRefreshAmount: limits.maxPerMinute || limits.maxPerSecond ? (limits.maxPerSecond || 0) * 60 + (limits.maxPerMinute || 0) : undefined,
    reservoirRefreshInterval: 60 * 1000,
  });

  // Add daily limits if specified
  if (limits.maxPerDay) {
    const dailyLimiter = new Bottleneck({
      reservoir: limits.maxPerDay,
      reservoirRefreshAmount: limits.maxPerDay,
      reservoirRefreshInterval: 24 * 60 * 60 * 1000,
    });
    limiter.chain(dailyLimiter);
  }

  limiter.on('failed', (error, jobInfo) => {
    console.warn(`[RateLimiter:${provider}] Job failed:`, error.message);
    if (jobInfo.retryCount < 3) {
      return 1000 * Math.pow(2, jobInfo.retryCount); // Exponential backoff
    }
  });

  limiters.set(provider, limiter);
  return limiter;
}

export function wrapWithLimiter<T>(
  provider: string,
  fn: () => Promise<T>
): Promise<T> {
  return getLimiter(provider).schedule(fn);
}

export function getProviderStatus(provider: string): {
  running: number;
  queued: number;
  reservoir: number | null;
} {
  const limiter = limiters.get(provider);
  if (!limiter) return { running: 0, queued: 0, reservoir: null };
  
  const counts = limiter.counts();
  return {
    running: counts.RUNNING,
    queued: counts.QUEUED,
    reservoir: limiter.reservoir(),
  };
}

export function getAllProviderStatus(): Record<string, ReturnType<typeof getProviderStatus>> {
  const status: Record<string, ReturnType<typeof getProviderStatus>> = {};
  for (const provider of Object.keys(PROVIDER_LIMITS)) {
    status[provider] = getProviderStatus(provider);
  }
  return status;
}
```

### 1.3 Create Circuit Breaker Registry

**File: `server/lib/circuitBreaker.ts`**

```typescript
import CircuitBreaker from 'opossum';

interface BreakerOptions {
  timeout?: number;
  errorThresholdPercentage?: number;
  resetTimeout?: number;
  volumeThreshold?: number;
}

const DEFAULT_OPTIONS: BreakerOptions = {
  timeout: 10000,
  errorThresholdPercentage: 50,
  resetTimeout: 30000,
  volumeThreshold: 5,
};

const breakers: Map<string, CircuitBreaker<any[], any>> = new Map();

export function getBreaker<T>(
  name: string,
  fn: (...args: any[]) => Promise<T>,
  options?: BreakerOptions,
  fallback?: (...args: any[]) => T | Promise<T>
): CircuitBreaker<any[], T> {
  const key = name;
  
  if (breakers.has(key)) {
    return breakers.get(key)!;
  }

  const breaker = new CircuitBreaker(fn, {
    ...DEFAULT_OPTIONS,
    ...options,
    name,
  });

  if (fallback) {
    breaker.fallback(fallback);
  }

  breaker.on('open', () => {
    console.warn(`[CircuitBreaker:${name}] OPEN - failing fast`);
  });

  breaker.on('halfOpen', () => {
    console.info(`[CircuitBreaker:${name}] HALF-OPEN - testing`);
  });

  breaker.on('close', () => {
    console.info(`[CircuitBreaker:${name}] CLOSED - recovered`);
  });

  breaker.on('fallback', () => {
    console.info(`[CircuitBreaker:${name}] Using fallback`);
  });

  breakers.set(key, breaker);
  return breaker;
}

export function getBreakerStats(name: string): CircuitBreaker.Stats | null {
  const breaker = breakers.get(name);
  return breaker ? breaker.stats : null;
}

export function getAllBreakerStats(): Record<string, CircuitBreaker.Stats | null> {
  const stats: Record<string, CircuitBreaker.Stats | null> = {};
  for (const [name] of breakers) {
    stats[name] = getBreakerStats(name);
  }
  return stats;
}

export function resetBreaker(name: string): boolean {
  const breaker = breakers.get(name);
  if (breaker) {
    breaker.close();
    return true;
  }
  return false;
}
```

### 1.4 Create Multi-Provider Fallback Manager

**File: `server/lib/providerFallback.ts`**

```typescript
import { wrapWithLimiter } from './rateLimiter';
import { getBreaker } from './circuitBreaker';
import { ApiCache } from './apiCache';

export interface ProviderAdapter<T> {
  name: string;
  priority: number;
  costPerCall: number;
  isEnabled: () => boolean;
  fetch: (...args: any[]) => Promise<T>;
  normalize?: (data: any) => T;
}

export interface FallbackResult<T> {
  data: T;
  provider: string;
  cached: boolean;
  latencyMs: number;
}

export class ProviderFallbackManager<T> {
  private providers: ProviderAdapter<T>[];
  private cache: ApiCache;
  private cachePrefix: string;
  private cacheTTL: number;

  constructor(
    providers: ProviderAdapter<T>[],
    cache: ApiCache,
    cachePrefix: string,
    cacheTTLMs: number = 60000
  ) {
    this.providers = providers.sort((a, b) => a.priority - b.priority);
    this.cache = cache;
    this.cachePrefix = cachePrefix;
    this.cacheTTL = cacheTTLMs;
  }

  async fetch(cacheKey: string, ...args: any[]): Promise<FallbackResult<T>> {
    const fullCacheKey = `${this.cachePrefix}:${cacheKey}`;
    
    // Check cache first
    const cached = this.cache.get<T>(fullCacheKey);
    if (cached) {
      return {
        data: cached,
        provider: 'cache',
        cached: true,
        latencyMs: 0,
      };
    }

    const enabledProviders = this.providers.filter(p => p.isEnabled());
    const errors: Error[] = [];

    for (const provider of enabledProviders) {
      const startTime = Date.now();
      
      try {
        const breaker = getBreaker(
          `provider:${provider.name}`,
          async () => wrapWithLimiter(provider.name, () => provider.fetch(...args)),
          { timeout: 15000, resetTimeout: 60000 }
        );

        let data = await breaker.fire();
        
        if (provider.normalize) {
          data = provider.normalize(data);
        }

        // Cache successful result
        this.cache.set(fullCacheKey, data, this.cacheTTL);

        return {
          data,
          provider: provider.name,
          cached: false,
          latencyMs: Date.now() - startTime,
        };
      } catch (error) {
        errors.push(error as Error);
        console.warn(`[ProviderFallback] ${provider.name} failed:`, (error as Error).message);
        continue;
      }
    }

    // All providers failed - try stale cache
    const stale = this.cache.getStale<T>(fullCacheKey);
    if (stale) {
      console.warn(`[ProviderFallback] All providers failed, using stale cache`);
      return {
        data: stale,
        provider: 'stale-cache',
        cached: true,
        latencyMs: 0,
      };
    }

    throw new AggregateError(errors, `All ${enabledProviders.length} providers failed for ${cacheKey}`);
  }
}
```

---

## PHASE 2: FREE DATA SOURCE CONNECTORS

### 2.1 SEC EDGAR Connector (FREE - Government Data)

**File: `server/connectors/sec-edgar.ts`**

```typescript
import { z } from 'zod';
import { wrapWithLimiter } from '../lib/rateLimiter';
import { ApiCache } from '../lib/apiCache';

const SEC_BASE_URL = 'https://data.sec.gov';
const SEC_EDGAR_URL = 'https://www.sec.gov/cgi-bin/browse-edgar';

// IMPORTANT: SEC requires User-Agent with contact info
const SEC_USER_AGENT = `AI-Active-Trader/1.0 (contact@yourcompany.com)`;

const CompanyFactsSchema = z.object({
  cik: z.number(),
  entityName: z.string(),
  facts: z.object({
    'us-gaap': z.record(z.any()).optional(),
    'dei': z.record(z.any()).optional(),
  }),
});

const FilingSchema = z.object({
  accessionNumber: z.string(),
  filingDate: z.string(),
  form: z.string(),
  primaryDocument: z.string().optional(),
});

export interface SECFiling {
  accessionNumber: string;
  filingDate: Date;
  form: string;
  documentUrl: string;
}

export interface CompanyFundamentals {
  cik: string;
  ticker: string;
  name: string;
  revenue?: number;
  netIncome?: number;
  totalAssets?: number;
  totalLiabilities?: number;
  eps?: number;
  sharesOutstanding?: number;
  filingDate?: Date;
}

const cache = new ApiCache(300); // 5-minute cache

// CIK lookup cache (ticker -> CIK mapping)
const cikCache = new Map<string, string>();

async function fetchSEC(url: string): Promise<any> {
  return wrapWithLimiter('sec-edgar', async () => {
    const response = await fetch(url, {
      headers: {
        'User-Agent': SEC_USER_AGENT,
        'Accept': 'application/json',
      },
    });

    if (!response.ok) {
      throw new Error(`SEC API error: ${response.status} ${response.statusText}`);
    }

    return response.json();
  });
}

export async function getCIKByTicker(ticker: string): Promise<string | null> {
  const normalizedTicker = ticker.toUpperCase();
  
  if (cikCache.has(normalizedTicker)) {
    return cikCache.get(normalizedTicker)!;
  }

  try {
    const data = await fetchSEC(`${SEC_BASE_URL}/submissions/CIK${normalizedTicker}.json`);
    const cik = String(data.cik).padStart(10, '0');
    cikCache.set(normalizedTicker, cik);
    return cik;
  } catch {
    // Try company tickers file
    const tickersData = await fetchSEC(`${SEC_BASE_URL}/files/company_tickers.json`);
    for (const entry of Object.values(tickersData) as any[]) {
      if (entry.ticker === normalizedTicker) {
        const cik = String(entry.cik_str).padStart(10, '0');
        cikCache.set(normalizedTicker, cik);
        return cik;
      }
    }
    return null;
  }
}

export async function getCompanyFacts(ticker: string): Promise<CompanyFundamentals | null> {
  const cacheKey = `sec-facts-${ticker}`;
  const cached = cache.get<CompanyFundamentals>(cacheKey);
  if (cached) return cached;

  const cik = await getCIKByTicker(ticker);
  if (!cik) return null;

  try {
    const data = await fetchSEC(`${SEC_BASE_URL}/api/xbrl/companyfacts/CIK${cik}.json`);
    const parsed = CompanyFactsSchema.parse(data);

    const getLatestValue = (concept: string, namespace: string = 'us-gaap'): number | undefined => {
      const facts = parsed.facts[namespace]?.[concept]?.units?.USD;
      if (!facts || facts.length === 0) return undefined;
      // Get most recent annual (10-K) filing
      const annual = facts.filter((f: any) => f.form === '10-K').sort((a: any, b: any) => 
        new Date(b.end).getTime() - new Date(a.end).getTime()
      );
      return annual[0]?.val;
    };

    const fundamentals: CompanyFundamentals = {
      cik,
      ticker: ticker.toUpperCase(),
      name: parsed.entityName,
      revenue: getLatestValue('Revenues') || getLatestValue('RevenueFromContractWithCustomerExcludingAssessedTax'),
      netIncome: getLatestValue('NetIncomeLoss'),
      totalAssets: getLatestValue('Assets'),
      totalLiabilities: getLatestValue('Liabilities'),
      eps: getLatestValue('EarningsPerShareBasic'),
      sharesOutstanding: getLatestValue('CommonStockSharesOutstanding'),
    };

    cache.set(cacheKey, fundamentals, 3600000); // 1-hour cache for fundamentals
    return fundamentals;
  } catch (error) {
    console.error(`[SEC-EDGAR] Failed to fetch facts for ${ticker}:`, error);
    return null;
  }
}

export async function getRecentFilings(
  ticker: string,
  formTypes: string[] = ['10-K', '10-Q', '8-K'],
  limit: number = 10
): Promise<SECFiling[]> {
  const cik = await getCIKByTicker(ticker);
  if (!cik) return [];

  try {
    const data = await fetchSEC(`${SEC_BASE_URL}/submissions/CIK${cik}.json`);
    
    const filings: SECFiling[] = [];
    const recent = data.filings?.recent || data;

    for (let i = 0; i < Math.min(recent.accessionNumber?.length || 0, 100); i++) {
      const form = recent.form[i];
      if (!formTypes.includes(form)) continue;
      
      filings.push({
        accessionNumber: recent.accessionNumber[i],
        filingDate: new Date(recent.filingDate[i]),
        form,
        documentUrl: `https://www.sec.gov/Archives/edgar/data/${cik}/${recent.accessionNumber[i].replace(/-/g, '')}/${recent.primaryDocument?.[i] || 'index.html'}`,
      });

      if (filings.length >= limit) break;
    }

    return filings;
  } catch (error) {
    console.error(`[SEC-EDGAR] Failed to fetch filings for ${ticker}:`, error);
    return [];
  }
}

export async function getFilingText(filing: SECFiling): Promise<string | null> {
  try {
    const response = await wrapWithLimiter('sec-edgar', async () => {
      return fetch(filing.documentUrl, {
        headers: { 'User-Agent': SEC_USER_AGENT },
      });
    });

    if (!response.ok) return null;
    return response.text();
  } catch {
    return null;
  }
}

// Bulk data download URLs for backtesting
export const SEC_BULK_DATA = {
  companyFacts: 'https://www.sec.gov/Archives/edgar/daily-index/xbrl/companyfacts.zip',
  submissions: 'https://www.sec.gov/Archives/edgar/daily-index/bulkdata/submissions.zip',
  financialStatements: (year: number, quarter: number) =>
    `https://www.sec.gov/files/dera/data/financial-statement-data-sets/${year}q${quarter}.zip`,
};
```

### 2.2 FRED Economic Data Connector (FREE - Federal Reserve)

**File: `server/connectors/fred.ts`**

```typescript
import { wrapWithLimiter } from '../lib/rateLimiter';
import { ApiCache } from '../lib/apiCache';

const FRED_BASE_URL = 'https://api.stlouisfed.org/fred';
const FRED_API_KEY = process.env.FRED_API_KEY; // Free key from https://fred.stlouisfed.org/docs/api/api_key.html

const cache = new ApiCache(600); // 10-minute cache

// Key economic series IDs
export const FRED_SERIES = {
  // Interest Rates
  FED_FUNDS_RATE: 'FEDFUNDS',
  TREASURY_10Y: 'DGS10',
  TREASURY_2Y: 'DGS2',
  TREASURY_3M: 'DTB3',
  YIELD_CURVE_SPREAD: 'T10Y2Y',
  
  // Inflation
  CPI: 'CPIAUCSL',
  CPI_YOY: 'CPIAUCSL',
  PCE: 'PCEPI',
  INFLATION_EXPECTATION: 'T5YIE',
  
  // Employment
  UNEMPLOYMENT_RATE: 'UNRATE',
  NONFARM_PAYROLLS: 'PAYEMS',
  INITIAL_CLAIMS: 'ICSA',
  
  // GDP & Growth
  GDP: 'GDP',
  GDP_GROWTH: 'A191RL1Q225SBEA',
  REAL_GDP: 'GDPC1',
  
  // Markets
  SP500: 'SP500',
  VIX: 'VIXCLS',
  NASDAQ: 'NASDAQCOM',
  
  // Housing
  HOUSING_STARTS: 'HOUST',
  HOME_PRICES: 'CSUSHPINSA',
  MORTGAGE_30Y: 'MORTGAGE30US',
  
  // Consumer
  CONSUMER_SENTIMENT: 'UMCSENT',
  RETAIL_SALES: 'RSXFS',
  
  // Business
  INDUSTRIAL_PRODUCTION: 'INDPRO',
  ISM_MANUFACTURING: 'MANEMP',
};

interface FredObservation {
  date: string;
  value: string;
}

interface FredSeriesInfo {
  id: string;
  title: string;
  frequency: string;
  units: string;
  lastUpdated: string;
}

export interface EconomicDataPoint {
  seriesId: string;
  title: string;
  date: Date;
  value: number;
  units: string;
  frequency: string;
}

async function fetchFRED(endpoint: string, params: Record<string, string> = {}): Promise<any> {
  if (!FRED_API_KEY) {
    throw new Error('FRED_API_KEY not configured');
  }

  const url = new URL(`${FRED_BASE_URL}/${endpoint}`);
  url.searchParams.set('api_key', FRED_API_KEY);
  url.searchParams.set('file_type', 'json');
  
  for (const [key, value] of Object.entries(params)) {
    url.searchParams.set(key, value);
  }

  return wrapWithLimiter('fred', async () => {
    const response = await fetch(url.toString());
    if (!response.ok) {
      throw new Error(`FRED API error: ${response.status}`);
    }
    return response.json();
  });
}

export async function getSeriesObservations(
  seriesId: string,
  options: {
    startDate?: string;
    endDate?: string;
    limit?: number;
    sort?: 'asc' | 'desc';
  } = {}
): Promise<EconomicDataPoint[]> {
  const cacheKey = `fred-${seriesId}-${JSON.stringify(options)}`;
  const cached = cache.get<EconomicDataPoint[]>(cacheKey);
  if (cached) return cached;

  try {
    // Get series info
    const seriesInfo = await fetchFRED('series', { series_id: seriesId });
    const info: FredSeriesInfo = seriesInfo.seriess[0];

    // Get observations
    const params: Record<string, string> = {
      series_id: seriesId,
      sort_order: options.sort || 'desc',
    };
    
    if (options.startDate) params.observation_start = options.startDate;
    if (options.endDate) params.observation_end = options.endDate;
    if (options.limit) params.limit = String(options.limit);

    const data = await fetchFRED('series/observations', params);

    const observations: EconomicDataPoint[] = data.observations
      .filter((obs: FredObservation) => obs.value !== '.')
      .map((obs: FredObservation) => ({
        seriesId,
        title: info.title,
        date: new Date(obs.date),
        value: parseFloat(obs.value),
        units: info.units,
        frequency: info.frequency,
      }));

    cache.set(cacheKey, observations, 600000); // 10-minute cache
    return observations;
  } catch (error) {
    console.error(`[FRED] Failed to fetch ${seriesId}:`, error);
    return [];
  }
}

export async function getLatestValue(seriesId: string): Promise<EconomicDataPoint | null> {
  const observations = await getSeriesObservations(seriesId, { limit: 1, sort: 'desc' });
  return observations[0] || null;
}

export async function getMacroSnapshot(): Promise<Record<string, EconomicDataPoint | null>> {
  const keySeries = [
    FRED_SERIES.FED_FUNDS_RATE,
    FRED_SERIES.TREASURY_10Y,
    FRED_SERIES.YIELD_CURVE_SPREAD,
    FRED_SERIES.CPI_YOY,
    FRED_SERIES.UNEMPLOYMENT_RATE,
    FRED_SERIES.VIX,
    FRED_SERIES.CONSUMER_SENTIMENT,
  ];

  const results = await Promise.all(
    keySeries.map(async (series) => ({
      series,
      data: await getLatestValue(series),
    }))
  );

  return Object.fromEntries(results.map(r => [r.series, r.data]));
}

export function interpretMacroRegime(snapshot: Record<string, EconomicDataPoint | null>): {
  regime: 'risk-on' | 'risk-off' | 'neutral';
  score: number; // -1 to +1
  factors: string[];
} {
  const factors: string[] = [];
  let score = 0;

  const vix = snapshot[FRED_SERIES.VIX]?.value;
  if (vix !== undefined) {
    if (vix < 15) { score += 0.3; factors.push('Low VIX (risk-on)'); }
    else if (vix > 25) { score -= 0.3; factors.push('High VIX (risk-off)'); }
  }

  const yieldCurve = snapshot[FRED_SERIES.YIELD_CURVE_SPREAD]?.value;
  if (yieldCurve !== undefined) {
    if (yieldCurve < 0) { score -= 0.2; factors.push('Inverted yield curve'); }
    else if (yieldCurve > 1) { score += 0.1; factors.push('Steep yield curve'); }
  }

  const sentiment = snapshot[FRED_SERIES.CONSUMER_SENTIMENT]?.value;
  if (sentiment !== undefined) {
    if (sentiment > 90) { score += 0.2; factors.push('High consumer sentiment'); }
    else if (sentiment < 70) { score -= 0.2; factors.push('Low consumer sentiment'); }
  }

  return {
    regime: score > 0.2 ? 'risk-on' : score < -0.2 ? 'risk-off' : 'neutral',
    score: Math.max(-1, Math.min(1, score)),
    factors,
  };
}
```

### 2.3 Binance Crypto Data Connector (FREE - No Auth Required)

**File: `server/connectors/binance.ts`**

```typescript
import { z } from 'zod';
import { wrapWithLimiter } from '../lib/rateLimiter';
import { ApiCache } from '../lib/apiCache';
import ReconnectingWebSocket from 'reconnecting-websocket';
import WebSocket from 'ws';

const BINANCE_API = 'https://api.binance.com/api/v3';
const BINANCE_WS = 'wss://stream.binance.com:9443/ws';

const cache = new ApiCache(30); // 30-second cache for prices

// Symbol mapping: Common names -> Binance symbols
const SYMBOL_MAP: Record<string, string> = {
  'BTC': 'BTCUSDT',
  'ETH': 'ETHUSDT',
  'SOL': 'SOLUSDT',
  'BNB': 'BNBUSDT',
  'XRP': 'XRPUSDT',
  'ADA': 'ADAUSDT',
  'DOGE': 'DOGEUSDT',
  'DOT': 'DOTUSDT',
  'AVAX': 'AVAXUSDT',
  'MATIC': 'MATICUSDT',
};

const TickerSchema = z.object({
  symbol: z.string(),
  priceChange: z.string(),
  priceChangePercent: z.string(),
  lastPrice: z.string(),
  volume: z.string(),
  quoteVolume: z.string(),
  highPrice: z.string(),
  lowPrice: z.string(),
});

const KlineSchema = z.object({
  openTime: z.number(),
  open: z.string(),
  high: z.string(),
  low: z.string(),
  close: z.string(),
  volume: z.string(),
  closeTime: z.number(),
});

export interface CryptoQuote {
  symbol: string;
  price: number;
  change24h: number;
  changePercent24h: number;
  volume24h: number;
  high24h: number;
  low24h: number;
  timestamp: Date;
}

export interface CryptoOHLCV {
  timestamp: Date;
  open: number;
  high: number;
  low: number;
  close: number;
  volume: number;
}

function toBinanceSymbol(symbol: string): string {
  const upper = symbol.toUpperCase();
  return SYMBOL_MAP[upper] || (upper.endsWith('USDT') ? upper : `${upper}USDT`);
}

async function fetchBinance(endpoint: string, params: Record<string, string> = {}): Promise<any> {
  const url = new URL(`${BINANCE_API}${endpoint}`);
  for (const [key, value] of Object.entries(params)) {
    url.searchParams.set(key, value);
  }

  return wrapWithLimiter('binance', async () => {
    const response = await fetch(url.toString());
    if (!response.ok) {
      const error = await response.json().catch(() => ({}));
      throw new Error(`Binance API error: ${response.status} - ${error.msg || response.statusText}`);
    }
    return response.json();
  });
}

export async function getCryptoQuote(symbol: string): Promise<CryptoQuote | null> {
  const binanceSymbol = toBinanceSymbol(symbol);
  const cacheKey = `binance-quote-${binanceSymbol}`;
  
  const cached = cache.get<CryptoQuote>(cacheKey);
  if (cached) return cached;

  try {
    const data = await fetchBinance('/ticker/24hr', { symbol: binanceSymbol });
    const parsed = TickerSchema.parse(data);

    const quote: CryptoQuote = {
      symbol: symbol.toUpperCase(),
      price: parseFloat(parsed.lastPrice),
      change24h: parseFloat(parsed.priceChange),
      changePercent24h: parseFloat(parsed.priceChangePercent),
      volume24h: parseFloat(parsed.quoteVolume),
      high24h: parseFloat(parsed.highPrice),
      low24h: parseFloat(parsed.lowPrice),
      timestamp: new Date(),
    };

    cache.set(cacheKey, quote, 15000); // 15-second cache
    return quote;
  } catch (error) {
    console.error(`[Binance] Failed to fetch quote for ${symbol}:`, error);
    return null;
  }
}

export async function getCryptoOHLCV(
  symbol: string,
  interval: '1m' | '5m' | '15m' | '1h' | '4h' | '1d' = '1h',
  limit: number = 100
): Promise<CryptoOHLCV[]> {
  const binanceSymbol = toBinanceSymbol(symbol);
  
  try {
    const data = await fetchBinance('/klines', {
      symbol: binanceSymbol,
      interval,
      limit: String(limit),
    });

    return data.map((k: any[]) => ({
      timestamp: new Date(k[0]),
      open: parseFloat(k[1]),
      high: parseFloat(k[2]),
      low: parseFloat(k[3]),
      close: parseFloat(k[4]),
      volume: parseFloat(k[5]),
    }));
  } catch (error) {
    console.error(`[Binance] Failed to fetch OHLCV for ${symbol}:`, error);
    return [];
  }
}

export async function getMultipleQuotes(symbols: string[]): Promise<Map<string, CryptoQuote>> {
  const results = new Map<string, CryptoQuote>();

  // Binance allows fetching all tickers at once
  try {
    const allTickers = await fetchBinance('/ticker/24hr');
    const tickerMap = new Map(allTickers.map((t: any) => [t.symbol, t]));

    for (const symbol of symbols) {
      const binanceSymbol = toBinanceSymbol(symbol);
      const ticker = tickerMap.get(binanceSymbol);
      
      if (ticker) {
        const parsed = TickerSchema.parse(ticker);
        results.set(symbol.toUpperCase(), {
          symbol: symbol.toUpperCase(),
          price: parseFloat(parsed.lastPrice),
          change24h: parseFloat(parsed.priceChange),
          changePercent24h: parseFloat(parsed.priceChangePercent),
          volume24h: parseFloat(parsed.quoteVolume),
          high24h: parseFloat(parsed.highPrice),
          low24h: parseFloat(parsed.lowPrice),
          timestamp: new Date(),
        });
      }
    }
  } catch (error) {
    console.error('[Binance] Failed to fetch multiple quotes:', error);
  }

  return results;
}

// WebSocket for real-time prices
export class BinancePriceStream {
  private ws: ReconnectingWebSocket | null = null;
  private subscriptions: Set<string> = new Set();
  private callbacks: Map<string, Set<(quote: CryptoQuote) => void>> = new Map();

  connect(symbols: string[]): void {
    const streams = symbols.map(s => `${toBinanceSymbol(s).toLowerCase()}@ticker`).join('/');
    const url = `${BINANCE_WS}/${streams}`;

    this.ws = new ReconnectingWebSocket(url, [], {
      WebSocket: WebSocket as any,
      maxReconnectionDelay: 10000,
      minReconnectionDelay: 1000,
      reconnectionDelayGrowFactor: 1.3,
    });

    this.ws.addEventListener('message', (event) => {
      try {
        const data = JSON.parse(event.data as string);
        const symbol = data.s?.replace('USDT', '') || '';
        
        const quote: CryptoQuote = {
          symbol,
          price: parseFloat(data.c),
          change24h: parseFloat(data.p),
          changePercent24h: parseFloat(data.P),
          volume24h: parseFloat(data.q),
          high24h: parseFloat(data.h),
          low24h: parseFloat(data.l),
          timestamp: new Date(),
        };

        // Update cache
        cache.set(`binance-quote-${data.s}`, quote, 15000);

        // Notify subscribers
        const cbs = this.callbacks.get(symbol);
        if (cbs) {
          cbs.forEach(cb => cb(quote));
        }
      } catch (e) {
        // Ignore parse errors
      }
    });

    symbols.forEach(s => this.subscriptions.add(s.toUpperCase()));
  }

  subscribe(symbol: string, callback: (quote: CryptoQuote) => void): () => void {
    const upper = symbol.toUpperCase();
    if (!this.callbacks.has(upper)) {
      this.callbacks.set(upper, new Set());
    }
    this.callbacks.get(upper)!.add(callback);

    return () => {
      this.callbacks.get(upper)?.delete(callback);
    };
  }

  disconnect(): void {
    this.ws?.close();
    this.ws = null;
    this.subscriptions.clear();
    this.callbacks.clear();
  }
}

export const binancePriceStream = new BinancePriceStream();
```

### 2.4 DeFiLlama Connector (FREE - No Auth Required)

**File: `server/connectors/defillama.ts`**

```typescript
import { wrapWithLimiter } from '../lib/rateLimiter';
import { ApiCache } from '../lib/apiCache';

const DEFILLAMA_API = 'https://api.llama.fi';
const DEFILLAMA_YIELDS = 'https://yields.llama.fi';
const DEFILLAMA_COINS = 'https://coins.llama.fi';
const DEFILLAMA_STABLECOINS = 'https://stablecoins.llama.fi';

const cache = new ApiCache(300); // 5-minute cache

export interface Protocol {
  id: string;
  name: string;
  symbol: string;
  chain: string;
  tvl: number;
  change_1d: number;
  change_7d: number;
  category: string;
}

export interface YieldPool {
  pool: string;
  chain: string;
  project: string;
  symbol: string;
  tvlUsd: number;
  apy: number;
  apyBase: number;
  apyReward: number;
  stablecoin: boolean;
}

export interface StablecoinData {
  id: string;
  name: string;
  symbol: string;
  circulating: number;
  circulatingPrevDay: number;
  chains: string[];
}

async function fetchDefiLlama(baseUrl: string, endpoint: string): Promise<any> {
  return wrapWithLimiter('defillama', async () => {
    const response = await fetch(`${baseUrl}${endpoint}`);
    if (!response.ok) {
      throw new Error(`DeFiLlama API error: ${response.status}`);
    }
    return response.json();
  });
}

export async function getProtocols(): Promise<Protocol[]> {
  const cacheKey = 'defillama-protocols';
  const cached = cache.get<Protocol[]>(cacheKey);
  if (cached) return cached;

  try {
    const data = await fetchDefiLlama(DEFILLAMA_API, '/protocols');
    
    const protocols: Protocol[] = data.map((p: any) => ({
      id: p.slug,
      name: p.name,
      symbol: p.symbol || '',
      chain: p.chain || 'Multi-chain',
      tvl: p.tvl || 0,
      change_1d: p.change_1d || 0,
      change_7d: p.change_7d || 0,
      category: p.category || 'Other',
    }));

    cache.set(cacheKey, protocols, 300000); // 5-minute cache
    return protocols;
  } catch (error) {
    console.error('[DeFiLlama] Failed to fetch protocols:', error);
    return [];
  }
}

export async function getProtocolTVL(protocol: string): Promise<{
  tvl: number;
  tvlHistory: { date: Date; tvl: number }[];
} | null> {
  try {
    const data = await fetchDefiLlama(DEFILLAMA_API, `/protocol/${protocol}`);
    
    return {
      tvl: data.tvl?.[data.tvl.length - 1]?.totalLiquidityUSD || 0,
      tvlHistory: (data.tvl || []).map((t: any) => ({
        date: new Date(t.date * 1000),
        tvl: t.totalLiquidityUSD,
      })),
    };
  } catch (error) {
    console.error(`[DeFiLlama] Failed to fetch protocol ${protocol}:`, error);
    return null;
  }
}

export async function getChainTVL(chain: string): Promise<number> {
  try {
    const data = await fetchDefiLlama(DEFILLAMA_API, `/v2/chains`);
    const chainData = data.find((c: any) => 
      c.name.toLowerCase() === chain.toLowerCase()
    );
    return chainData?.tvl || 0;
  } catch {
    return 0;
  }
}

export async function getYieldPools(options: {
  chain?: string;
  project?: string;
  minTvl?: number;
  stablecoinOnly?: boolean;
} = {}): Promise<YieldPool[]> {
  const cacheKey = `defillama-yields-${JSON.stringify(options)}`;
  const cached = cache.get<YieldPool[]>(cacheKey);
  if (cached) return cached;

  try {
    const data = await fetchDefiLlama(DEFILLAMA_YIELDS, '/pools');
    
    let pools: YieldPool[] = data.data.map((p: any) => ({
      pool: p.pool,
      chain: p.chain,
      project: p.project,
      symbol: p.symbol,
      tvlUsd: p.tvlUsd,
      apy: p.apy,
      apyBase: p.apyBase || 0,
      apyReward: p.apyReward || 0,
      stablecoin: p.stablecoin || false,
    }));

    // Apply filters
    if (options.chain) {
      pools = pools.filter(p => p.chain.toLowerCase() === options.chain!.toLowerCase());
    }
    if (options.project) {
      pools = pools.filter(p => p.project.toLowerCase() === options.project!.toLowerCase());
    }
    if (options.minTvl) {
      pools = pools.filter(p => p.tvlUsd >= options.minTvl!);
    }
    if (options.stablecoinOnly) {
      pools = pools.filter(p => p.stablecoin);
    }

    cache.set(cacheKey, pools, 300000);
    return pools;
  } catch (error) {
    console.error('[DeFiLlama] Failed to fetch yield pools:', error);
    return [];
  }
}

export async function getStablecoins(): Promise<StablecoinData[]> {
  const cacheKey = 'defillama-stablecoins';
  const cached = cache.get<StablecoinData[]>(cacheKey);
  if (cached) return cached;

  try {
    const data = await fetchDefiLlama(DEFILLAMA_STABLECOINS, '/stablecoins');
    
    const stablecoins: StablecoinData[] = data.peggedAssets.map((s: any) => ({
      id: s.id,
      name: s.name,
      symbol: s.symbol,
      circulating: s.circulating?.peggedUSD || 0,
      circulatingPrevDay: s.circulatingPrevDay?.peggedUSD || 0,
      chains: s.chains || [],
    }));

    cache.set(cacheKey, stablecoins, 300000);
    return stablecoins;
  } catch (error) {
    console.error('[DeFiLlama] Failed to fetch stablecoins:', error);
    return [];
  }
}

export async function getTokenPrice(
  chain: string,
  tokenAddress: string
): Promise<{ price: number; timestamp: Date } | null> {
  try {
    const data = await fetchDefiLlama(
      DEFILLAMA_COINS, 
      `/prices/current/${chain}:${tokenAddress}`
    );
    
    const coin = data.coins[`${chain}:${tokenAddress}`];
    if (!coin) return null;

    return {
      price: coin.price,
      timestamp: new Date(coin.timestamp * 1000),
    };
  } catch {
    return null;
  }
}

// DeFi health signals for trading
export async function getDeFiSignals(): Promise<{
  totalTVL: number;
  tvlChange24h: number;
  stablecoinSupply: number;
  stablecoinChange24h: number;
  topProtocols: Protocol[];
  sentiment: 'bullish' | 'bearish' | 'neutral';
}> {
  const [protocols, stablecoins] = await Promise.all([
    getProtocols(),
    getStablecoins(),
  ]);

  const totalTVL = protocols.reduce((sum, p) => sum + p.tvl, 0);
  const avgTVLChange = protocols.slice(0, 50).reduce((sum, p) => sum + p.change_1d, 0) / 50;

  const stablecoinSupply = stablecoins.reduce((sum, s) => sum + s.circulating, 0);
  const stablecoinPrevDay = stablecoins.reduce((sum, s) => sum + s.circulatingPrevDay, 0);
  const stablecoinChange = ((stablecoinSupply - stablecoinPrevDay) / stablecoinPrevDay) * 100;

  let sentiment: 'bullish' | 'bearish' | 'neutral' = 'neutral';
  if (avgTVLChange > 2 && stablecoinChange > 0) sentiment = 'bullish';
  else if (avgTVLChange < -2 || stablecoinChange < -1) sentiment = 'bearish';

  return {
    totalTVL,
    tvlChange24h: avgTVLChange,
    stablecoinSupply,
    stablecoinChange24h: stablecoinChange,
    topProtocols: protocols.slice(0, 20),
    sentiment,
  };
}
```

### 2.5 Alpha Vantage Connector (FREE - 25 calls/day)

**File: `server/connectors/alpha-vantage.ts`**

```typescript
import { wrapWithLimiter } from '../lib/rateLimiter';
import { ApiCache } from '../lib/apiCache';

const AV_BASE_URL = 'https://www.alphavantage.co/query';
const AV_API_KEY = process.env.ALPHA_VANTAGE_API_KEY;

// IMPORTANT: Only 25 calls/day on free tier - use sparingly!
const cache = new ApiCache(86400); // 24-hour cache to maximize free tier

export interface StockOverview {
  symbol: string;
  name: string;
  description: string;
  exchange: string;
  sector: string;
  industry: string;
  marketCap: number;
  peRatio: number;
  pegRatio: number;
  bookValue: number;
  dividendYield: number;
  eps: number;
  revenuePerShare: number;
  profitMargin: number;
  operatingMargin: number;
  returnOnAssets: number;
  returnOnEquity: number;
  quarterlyEarningsGrowth: number;
  quarterlyRevenueGrowth: number;
  analystTargetPrice: number;
  analystRatingBuy: number;
  analystRatingHold: number;
  analystRatingSell: number;
  beta: number;
  fiftyTwoWeekHigh: number;
  fiftyTwoWeekLow: number;
}

export interface TechnicalIndicator {
  timestamp: Date;
  value: number;
}

async function fetchAlphaVantage(params: Record<string, string>): Promise<any> {
  if (!AV_API_KEY) {
    throw new Error('ALPHA_VANTAGE_API_KEY not configured');
  }

  const url = new URL(AV_BASE_URL);
  url.searchParams.set('apikey', AV_API_KEY);
  
  for (const [key, value] of Object.entries(params)) {
    url.searchParams.set(key, value);
  }

  return wrapWithLimiter('alpha-vantage', async () => {
    const response = await fetch(url.toString());
    const data = await response.json();

    // Check for rate limit or error
    if (data['Note'] || data['Information']) {
      throw new Error(`Alpha Vantage limit: ${data['Note'] || data['Information']}`);
    }
    if (data['Error Message']) {
      throw new Error(`Alpha Vantage error: ${data['Error Message']}`);
    }

    return data;
  });
}

export async function getCompanyOverview(symbol: string): Promise<StockOverview | null> {
  const cacheKey = `av-overview-${symbol}`;
  const cached = cache.get<StockOverview>(cacheKey);
  if (cached) return cached;

  try {
    const data = await fetchAlphaVantage({
      function: 'OVERVIEW',
      symbol,
    });

    if (!data.Symbol) return null;

    const overview: StockOverview = {
      symbol: data.Symbol,
      name: data.Name,
      description: data.Description,
      exchange: data.Exchange,
      sector: data.Sector,
      industry: data.Industry,
      marketCap: parseFloat(data.MarketCapitalization) || 0,
      peRatio: parseFloat(data.PERatio) || 0,
      pegRatio: parseFloat(data.PEGRatio) || 0,
      bookValue: parseFloat(data.BookValue) || 0,
      dividendYield: parseFloat(data.DividendYield) || 0,
      eps: parseFloat(data.EPS) || 0,
      revenuePerShare: parseFloat(data.RevenuePerShareTTM) || 0,
      profitMargin: parseFloat(data.ProfitMargin) || 0,
      operatingMargin: parseFloat(data.OperatingMarginTTM) || 0,
      returnOnAssets: parseFloat(data.ReturnOnAssetsTTM) || 0,
      returnOnEquity: parseFloat(data.ReturnOnEquityTTM) || 0,
      quarterlyEarningsGrowth: parseFloat(data.QuarterlyEarningsGrowthYOY) || 0,
      quarterlyRevenueGrowth: parseFloat(data.QuarterlyRevenueGrowthYOY) || 0,
      analystTargetPrice: parseFloat(data.AnalystTargetPrice) || 0,
      analystRatingBuy: parseInt(data.AnalystRatingStrongBuy || '0') + parseInt(data.AnalystRatingBuy || '0'),
      analystRatingHold: parseInt(data.AnalystRatingHold || '0'),
      analystRatingSell: parseInt(data.AnalystRatingSell || '0') + parseInt(data.AnalystRatingStrongSell || '0'),
      beta: parseFloat(data.Beta) || 1,
      fiftyTwoWeekHigh: parseFloat(data['52WeekHigh']) || 0,
      fiftyTwoWeekLow: parseFloat(data['52WeekLow']) || 0,
    };

    cache.set(cacheKey, overview, 86400000); // 24-hour cache
    return overview;
  } catch (error) {
    console.error(`[AlphaVantage] Failed to fetch overview for ${symbol}:`, error);
    return null;
  }
}

export async function getRSI(
  symbol: string,
  interval: 'daily' | 'weekly' | 'monthly' = 'daily',
  period: number = 14
): Promise<TechnicalIndicator[]> {
  const cacheKey = `av-rsi-${symbol}-${interval}-${period}`;
  const cached = cache.get<TechnicalIndicator[]>(cacheKey);
  if (cached) return cached;

  try {
    const data = await fetchAlphaVantage({
      function: 'RSI',
      symbol,
      interval,
      time_period: String(period),
      series_type: 'close',
    });

    const key = `Technical Analysis: RSI`;
    const indicators: TechnicalIndicator[] = Object.entries(data[key] || {})
      .map(([date, values]: [string, any]) => ({
        timestamp: new Date(date),
        value: parseFloat(values.RSI),
      }))
      .sort((a, b) => b.timestamp.getTime() - a.timestamp.getTime());

    cache.set(cacheKey, indicators, 3600000); // 1-hour cache for technicals
    return indicators;
  } catch (error) {
    console.error(`[AlphaVantage] Failed to fetch RSI for ${symbol}:`, error);
    return [];
  }
}

export async function getMACD(
  symbol: string,
  interval: 'daily' | 'weekly' | 'monthly' = 'daily'
): Promise<{
  timestamp: Date;
  macd: number;
  signal: number;
  histogram: number;
}[]> {
  const cacheKey = `av-macd-${symbol}-${interval}`;
  const cached = cache.get<any[]>(cacheKey);
  if (cached) return cached;

  try {
    const data = await fetchAlphaVantage({
      function: 'MACD',
      symbol,
      interval,
      series_type: 'close',
    });

    const key = `Technical Analysis: MACD`;
    const indicators = Object.entries(data[key] || {})
      .map(([date, values]: [string, any]) => ({
        timestamp: new Date(date),
        macd: parseFloat(values.MACD),
        signal: parseFloat(values.MACD_Signal),
        histogram: parseFloat(values.MACD_Hist),
      }))
      .sort((a, b) => b.timestamp.getTime() - a.timestamp.getTime());

    cache.set(cacheKey, indicators, 3600000);
    return indicators;
  } catch (error) {
    console.error(`[AlphaVantage] Failed to fetch MACD for ${symbol}:`, error);
    return [];
  }
}

// Daily call budget tracker
let dailyCallCount = 0;
let lastResetDate = new Date().toDateString();

export function checkBudget(): { remaining: number; resetAt: Date } {
  const today = new Date().toDateString();
  if (today !== lastResetDate) {
    dailyCallCount = 0;
    lastResetDate = today;
  }

  const resetAt = new Date();
  resetAt.setHours(24, 0, 0, 0);

  return {
    remaining: 25 - dailyCallCount,
    resetAt,
  };
}

export function incrementBudget(): void {
  dailyCallCount++;
}
```

---

## PHASE 3: SOCIAL MEDIA LISTENERS

### 3.1 Reddit Sentiment Connector (FREE - 100 req/min)

**File: `server/connectors/reddit.ts`**

```typescript
import Snoowrap from 'snoowrap';
import { wrapWithLimiter } from '../lib/rateLimiter';
import { ApiCache } from '../lib/apiCache';

// Reddit OAuth credentials (free)
const reddit = new Snoowrap({
  userAgent: 'AI-Active-Trader/1.0',
  clientId: process.env.REDDIT_CLIENT_ID,
  clientSecret: process.env.REDDIT_CLIENT_SECRET,
  username: process.env.REDDIT_USERNAME,
  password: process.env.REDDIT_PASSWORD,
});

const cache = new ApiCache(300); // 5-minute cache

// Subreddits to monitor
const TRADING_SUBREDDITS = {
  equities: ['wallstreetbets', 'stocks', 'investing', 'options', 'stockmarket'],
  crypto: ['cryptocurrency', 'bitcoin', 'ethereum', 'altcoin', 'defi'],
};

export interface RedditPost {
  id: string;
  title: string;
  selftext: string;
  author: string;
  subreddit: string;
  score: number;
  upvoteRatio: number;
  numComments: number;
  created: Date;
  url: string;
  symbols: string[];
}

export interface RedditSentiment {
  symbol: string;
  mentions: number;
  averageScore: number;
  averageUpvoteRatio: number;
  sentiment: number; // -1 to +1
  topPosts: RedditPost[];
  source: 'reddit';
  timestamp: Date;
}

// Extract ticker symbols from text
function extractSymbols(text: string): string[] {
  const patterns = [
    /\$([A-Z]{1,5})\b/g,  // $AAPL format
    /\b([A-Z]{2,5})\b(?=.*(?:stock|share|call|put|option|buy|sell|long|short))/gi,
  ];
  
  const symbols = new Set<string>();
  
  for (const pattern of patterns) {
    const matches = text.matchAll(pattern);
    for (const match of matches) {
      const symbol = match[1].toUpperCase();
      // Filter out common words that look like tickers
      if (!['I', 'A', 'AT', 'IT', 'FOR', 'THE', 'AND', 'OR', 'ON', 'IN', 'TO', 'DD', 'TA', 'CEO', 'CFO', 'IPO', 'ETF', 'USD', 'ATH', 'ATL', 'YOLO', 'FOMO'].includes(symbol)) {
        symbols.add(symbol);
      }
    }
  }
  
  return Array.from(symbols);
}

export async function getSubredditPosts(
  subreddit: string,
  options: {
    sort?: 'hot' | 'new' | 'top' | 'rising';
    time?: 'hour' | 'day' | 'week' | 'month' | 'year' | 'all';
    limit?: number;
  } = {}
): Promise<RedditPost[]> {
  const cacheKey = `reddit-${subreddit}-${options.sort || 'hot'}-${options.time || 'day'}`;
  const cached = cache.get<RedditPost[]>(cacheKey);
  if (cached) return cached;

  try {
    const posts = await wrapWithLimiter('reddit', async () => {
      const sub = reddit.getSubreddit(subreddit);
      
      switch (options.sort) {
        case 'new':
          return sub.getNew({ limit: options.limit || 25 });
        case 'top':
          return sub.getTop({ time: options.time || 'day', limit: options.limit || 25 });
        case 'rising':
          return sub.getRising({ limit: options.limit || 25 });
        default:
          return sub.getHot({ limit: options.limit || 25 });
      }
    });

    const result: RedditPost[] = posts.map((post: any) => ({
      id: post.id,
      title: post.title,
      selftext: post.selftext || '',
      author: post.author?.name || '[deleted]',
      subreddit: post.subreddit?.display_name || subreddit,
      score: post.score,
      upvoteRatio: post.upvote_ratio,
      numComments: post.num_comments,
      created: new Date(post.created_utc * 1000),
      url: `https://reddit.com${post.permalink}`,
      symbols: extractSymbols(`${post.title} ${post.selftext}`),
    }));

    cache.set(cacheKey, result, 300000);
    return result;
  } catch (error) {
    console.error(`[Reddit] Failed to fetch ${subreddit}:`, error);
    return [];
  }
}

export async function getSymbolMentions(
  symbol: string,
  assetType: 'equities' | 'crypto' = 'equities'
): Promise<RedditSentiment> {
  const cacheKey = `reddit-mentions-${symbol}-${assetType}`;
  const cached = cache.get<RedditSentiment>(cacheKey);
  if (cached) return cached;

  const subreddits = TRADING_SUBREDDITS[assetType];
  const allPosts: RedditPost[] = [];

  for (const sub of subreddits) {
    const posts = await getSubredditPosts(sub, { sort: 'hot', limit: 50 });
    allPosts.push(...posts);
  }

  // Filter to posts mentioning this symbol
  const mentioningPosts = allPosts.filter(post => 
    post.symbols.includes(symbol.toUpperCase()) ||
    post.title.toUpperCase().includes(symbol.toUpperCase()) ||
    post.selftext.toUpperCase().includes(symbol.toUpperCase())
  );

  // Calculate sentiment based on engagement metrics
  let sentiment = 0;
  if (mentioningPosts.length > 0) {
    const avgUpvoteRatio = mentioningPosts.reduce((sum, p) => sum + p.upvoteRatio, 0) / mentioningPosts.length;
    const avgScore = mentioningPosts.reduce((sum, p) => sum + p.score, 0) / mentioningPosts.length;
    
    // Normalize: upvote ratio > 0.7 is bullish, < 0.4 is bearish
    sentiment = (avgUpvoteRatio - 0.5) * 2;
    
    // Weight by engagement (high score = more conviction)
    const engagementMultiplier = Math.min(Math.log10(avgScore + 1) / 3, 1);
    sentiment *= engagementMultiplier;
  }

  const result: RedditSentiment = {
    symbol: symbol.toUpperCase(),
    mentions: mentioningPosts.length,
    averageScore: mentioningPosts.length > 0 
      ? mentioningPosts.reduce((sum, p) => sum + p.score, 0) / mentioningPosts.length 
      : 0,
    averageUpvoteRatio: mentioningPosts.length > 0
      ? mentioningPosts.reduce((sum, p) => sum + p.upvoteRatio, 0) / mentioningPosts.length
      : 0,
    sentiment: Math.max(-1, Math.min(1, sentiment)),
    topPosts: mentioningPosts
      .sort((a, b) => b.score - a.score)
      .slice(0, 5),
    source: 'reddit',
    timestamp: new Date(),
  };

  cache.set(cacheKey, result, 300000);
  return result;
}

export async function getTrendingTickers(
  assetType: 'equities' | 'crypto' = 'equities'
): Promise<{ symbol: string; mentions: number; sentiment: number }[]> {
  const subreddits = TRADING_SUBREDDITS[assetType];
  const symbolCounts = new Map<string, { count: number; scores: number[] }>();

  for (const sub of subreddits) {
    const posts = await getSubredditPosts(sub, { sort: 'hot', limit: 100 });
    
    for (const post of posts) {
      for (const symbol of post.symbols) {
        const existing = symbolCounts.get(symbol) || { count: 0, scores: [] };
        existing.count++;
        existing.scores.push(post.upvoteRatio);
        symbolCounts.set(symbol, existing);
      }
    }
  }

  return Array.from(symbolCounts.entries())
    .map(([symbol, data]) => ({
      symbol,
      mentions: data.count,
      sentiment: (data.scores.reduce((a, b) => a + b, 0) / data.scores.length - 0.5) * 2,
    }))
    .sort((a, b) => b.mentions - a.mentions)
    .slice(0, 20);
}
```

### 3.2 StockTwits Connector (FREE)

**File: `server/connectors/stocktwits.ts`**

```typescript
import { wrapWithLimiter } from '../lib/rateLimiter';
import { ApiCache } from '../lib/apiCache';

const STOCKTWITS_API = 'https://api.stocktwits.com/api/2';

const cache = new ApiCache(180); // 3-minute cache

export interface StockTwit {
  id: number;
  body: string;
  createdAt: Date;
  sentiment: 'bullish' | 'bearish' | null;
  user: {
    username: string;
    followers: number;
  };
  likes: number;
  reshares: number;
}

export interface StockTwitsSentiment {
  symbol: string;
  sentimentScore: number; // -1 to +1
  bullishCount: number;
  bearishCount: number;
  totalMessages: number;
  watchlistCount: number;
  trending: boolean;
  recentTwits: StockTwit[];
  source: 'stocktwits';
  timestamp: Date;
}

async function fetchStockTwits(endpoint: string): Promise<any> {
  return wrapWithLimiter('stocktwits', async () => {
    const response = await fetch(`${STOCKTWITS_API}${endpoint}`);
    if (!response.ok) {
      throw new Error(`StockTwits API error: ${response.status}`);
    }
    return response.json();
  });
}

export async function getSymbolStream(symbol: string): Promise<StockTwitsSentiment> {
  const cacheKey = `stocktwits-${symbol}`;
  const cached = cache.get<StockTwitsSentiment>(cacheKey);
  if (cached) return cached;

  try {
    const data = await fetchStockTwits(`/streams/symbol/${symbol.toUpperCase()}.json`);

    const messages: StockTwit[] = (data.messages || []).map((m: any) => ({
      id: m.id,
      body: m.body,
      createdAt: new Date(m.created_at),
      sentiment: m.entities?.sentiment?.basic || null,
      user: {
        username: m.user?.username || 'unknown',
        followers: m.user?.followers || 0,
      },
      likes: m.likes?.total || 0,
      reshares: m.reshares?.total || 0,
    }));

    // Calculate sentiment
    const bullish = messages.filter(m => m.sentiment === 'bullish').length;
    const bearish = messages.filter(m => m.sentiment === 'bearish').length;
    const total = bullish + bearish;
    
    const sentimentScore = total > 0 
      ? ((bullish - bearish) / total)
      : 0;

    const result: StockTwitsSentiment = {
      symbol: data.symbol?.symbol || symbol.toUpperCase(),
      sentimentScore,
      bullishCount: bullish,
      bearishCount: bearish,
      totalMessages: messages.length,
      watchlistCount: data.symbol?.watchlist_count || 0,
      trending: data.symbol?.is_trending || false,
      recentTwits: messages.slice(0, 10),
      source: 'stocktwits',
      timestamp: new Date(),
    };

    cache.set(cacheKey, result, 180000);
    return result;
  } catch (error) {
    console.error(`[StockTwits] Failed to fetch ${symbol}:`, error);
    return {
      symbol: symbol.toUpperCase(),
      sentimentScore: 0,
      bullishCount: 0,
      bearishCount: 0,
      totalMessages: 0,
      watchlistCount: 0,
      trending: false,
      recentTwits: [],
      source: 'stocktwits',
      timestamp: new Date(),
    };
  }
}

export async function getTrendingSymbols(): Promise<{
  symbol: string;
  title: string;
  watchlistCount: number;
}[]> {
  const cacheKey = 'stocktwits-trending';
  const cached = cache.get<any[]>(cacheKey);
  if (cached) return cached;

  try {
    const data = await fetchStockTwits('/trending/symbols.json');
    
    const symbols = (data.symbols || []).map((s: any) => ({
      symbol: s.symbol,
      title: s.title,
      watchlistCount: s.watchlist_count,
    }));

    cache.set(cacheKey, symbols, 300000);
    return symbols;
  } catch (error) {
    console.error('[StockTwits] Failed to fetch trending:', error);
    return [];
  }
}

export async function getSymbolSentimentBatch(symbols: string[]): Promise<Map<string, StockTwitsSentiment>> {
  const results = new Map<string, StockTwitsSentiment>();
  
  // StockTwits doesn't have a batch endpoint, so we fetch sequentially with rate limiting
  for (const symbol of symbols) {
    const sentiment = await getSymbolStream(symbol);
    results.set(symbol.toUpperCase(), sentiment);
  }
  
  return results;
}
```

### 3.3 Unified Social Sentiment Aggregator

**File: `server/services/social-sentiment-aggregator.ts`**

```typescript
import { getSymbolMentions, RedditSentiment } from '../connectors/reddit';
import { getSymbolStream, StockTwitsSentiment } from '../connectors/stocktwits';
import { ApiCache } from '../lib/apiCache';

const cache = new ApiCache(300);

export interface UnifiedSentiment {
  symbol: string;
  overallScore: number; // -1 to +1
  confidence: number; // 0 to 1 (based on data volume)
  sources: {
    reddit?: RedditSentiment;
    stocktwits?: StockTwitsSentiment;
  };
  breakdown: {
    source: string;
    score: number;
    weight: number;
    mentions: number;
  }[];
  timestamp: Date;
}

// Source weights based on signal quality
const SOURCE_WEIGHTS = {
  stocktwits: 0.40,  // Highest: explicit bull/bear tags
  reddit: 0.35,      // Good: high engagement community
  twitter: 0.25,     // Would need paid API
};

export async function getUnifiedSentiment(
  symbol: string,
  assetType: 'equities' | 'crypto' = 'equities'
): Promise<UnifiedSentiment> {
  const cacheKey = `unified-sentiment-${symbol}-${assetType}`;
  const cached = cache.get<UnifiedSentiment>(cacheKey);
  if (cached) return cached;

  // Fetch from all available sources in parallel
  const [redditData, stocktwitsData] = await Promise.all([
    getSymbolMentions(symbol, assetType).catch(() => null),
    getSymbolStream(symbol).catch(() => null),
  ]);

  const breakdown: UnifiedSentiment['breakdown'] = [];
  let weightedSum = 0;
  let totalWeight = 0;
  let totalMentions = 0;

  // Process Reddit
  if (redditData && redditData.mentions > 0) {
    const weight = SOURCE_WEIGHTS.reddit * Math.min(redditData.mentions / 10, 1); // Scale by volume
    breakdown.push({
      source: 'reddit',
      score: redditData.sentiment,
      weight,
      mentions: redditData.mentions,
    });
    weightedSum += redditData.sentiment * weight;
    totalWeight += weight;
    totalMentions += redditData.mentions;
  }

  // Process StockTwits
  if (stocktwitsData && stocktwitsData.totalMessages > 0) {
    const weight = SOURCE_WEIGHTS.stocktwits * Math.min(stocktwitsData.totalMessages / 20, 1);
    breakdown.push({
      source: 'stocktwits',
      score: stocktwitsData.sentimentScore,
      weight,
      mentions: stocktwitsData.totalMessages,
    });
    weightedSum += stocktwitsData.sentimentScore * weight;
    totalWeight += weight;
    totalMentions += stocktwitsData.totalMessages;
  }

  // Calculate overall score
  const overallScore = totalWeight > 0 ? weightedSum / totalWeight : 0;
  
  // Confidence based on data volume and source diversity
  const sourceCount = breakdown.length;
  const volumeConfidence = Math.min(totalMentions / 50, 1);
  const diversityBonus = sourceCount > 1 ? 0.2 : 0;
  const confidence = Math.min((volumeConfidence + diversityBonus) * 0.8, 1);

  const result: UnifiedSentiment = {
    symbol: symbol.toUpperCase(),
    overallScore: Math.max(-1, Math.min(1, overallScore)),
    confidence,
    sources: {
      reddit: redditData || undefined,
      stocktwits: stocktwitsData || undefined,
    },
    breakdown,
    timestamp: new Date(),
  };

  cache.set(cacheKey, result, 300000);
  return result;
}

// Apply recency decay to sentiment scores
export function applyRecencyDecay(
  sentiment: UnifiedSentiment,
  halfLifeMinutes: number = 15
): number {
  const ageMinutes = (Date.now() - sentiment.timestamp.getTime()) / 60000;
  const decayFactor = Math.pow(0.5, ageMinutes / halfLifeMinutes);
  return sentiment.overallScore * decayFactor;
}

// Batch fetch for multiple symbols
export async function getBatchSentiment(
  symbols: string[],
  assetType: 'equities' | 'crypto' = 'equities'
): Promise<Map<string, UnifiedSentiment>> {
  const results = new Map<string, UnifiedSentiment>();
  
  // Process in parallel batches of 5 to respect rate limits
  const batchSize = 5;
  for (let i = 0; i < symbols.length; i += batchSize) {
    const batch = symbols.slice(i, i + batchSize);
    const batchResults = await Promise.all(
      batch.map(symbol => getUnifiedSentiment(symbol, assetType))
    );
    
    batch.forEach((symbol, idx) => {
      results.set(symbol.toUpperCase(), batchResults[idx]);
    });
  }
  
  return results;
}
```

---

## PHASE 4: HUGGING FACE ML INTEGRATIONS

### 4.1 Multi-Model Sentiment Service

**File: `server/services/ml-sentiment.ts`**

```typescript
import { pipeline, Pipeline } from '@xenova/transformers';
import { ApiCache } from '../lib/apiCache';
import { wrapWithLimiter } from '../lib/rateLimiter';

const cache = new ApiCache(300);

// Model instances (lazy-loaded)
let finbertPipeline: Pipeline | null = null;
let twitterSentimentPipeline: Pipeline | null = null;
let fastSentimentPipeline: Pipeline | null = null;

// Initialize models on first use
async function getFinBERTPipeline(): Promise<Pipeline> {
  if (!finbertPipeline) {
    console.log('[ML] Loading FinBERT model...');
    finbertPipeline = await pipeline(
      'sentiment-analysis',
      'Xenova/finbert' // ONNX version for browser/Node
    );
    console.log('[ML] FinBERT loaded');
  }
  return finbertPipeline;
}

async function getTwitterPipeline(): Promise<Pipeline> {
  if (!twitterSentimentPipeline) {
    console.log('[ML] Loading Twitter sentiment model...');
    twitterSentimentPipeline = await pipeline(
      'sentiment-analysis',
      'Xenova/twitter-roberta-base-sentiment-latest'
    );
    console.log('[ML] Twitter sentiment loaded');
  }
  return twitterSentimentPipeline;
}

async function getFastPipeline(): Promise<Pipeline> {
  if (!fastSentimentPipeline) {
    console.log('[ML] Loading fast sentiment model...');
    fastSentimentPipeline = await pipeline(
      'sentiment-analysis',
      'Xenova/distilbert-base-uncased-finetuned-sst-2-english'
    );
    console.log('[ML] Fast sentiment loaded');
  }
  return fastSentimentPipeline;
}

export interface SentimentResult {
  text: string;
  label: 'positive' | 'negative' | 'neutral';
  score: number; // -1 to +1 normalized
  confidence: number; // 0 to 1
  model: string;
}

// Normalize different model outputs to consistent -1 to +1 scale
function normalizeOutput(output: any, modelType: string): { label: string; score: number; confidence: number } {
  const result = output[0];
  
  switch (modelType) {
    case 'finbert':
      // FinBERT: positive/negative/neutral with score
      if (result.label === 'positive') {
        return { label: 'positive', score: result.score, confidence: result.score };
      } else if (result.label === 'negative') {
        return { label: 'negative', score: -result.score, confidence: result.score };
      }
      return { label: 'neutral', score: 0, confidence: result.score };
      
    case 'twitter':
      // Twitter RoBERTa: positive/negative/neutral
      if (result.label === 'positive' || result.label === 'POSITIVE') {
        return { label: 'positive', score: result.score, confidence: result.score };
      } else if (result.label === 'negative' || result.label === 'NEGATIVE') {
        return { label: 'negative', score: -result.score, confidence: result.score };
      }
      return { label: 'neutral', score: 0, confidence: result.score };
      
    case 'fast':
      // DistilBERT SST-2: POSITIVE/NEGATIVE only
      if (result.label === 'POSITIVE') {
        return { label: 'positive', score: result.score * 2 - 1, confidence: result.score };
      }
      return { label: 'negative', score: -(result.score * 2 - 1), confidence: result.score };
      
    default:
      return { label: 'neutral', score: 0, confidence: 0 };
  }
}

export async function analyzeSentiment(
  text: string,
  sourceType: 'news' | 'social' | 'filing' | 'general' = 'general'
): Promise<SentimentResult> {
  const cacheKey = `ml-sentiment-${sourceType}-${text.slice(0, 100)}`;
  const cached = cache.get<SentimentResult>(cacheKey);
  if (cached) return cached;

  try {
    let pipeline: Pipeline;
    let modelType: string;

    // Route to appropriate model based on source
    switch (sourceType) {
      case 'news':
      case 'filing':
        pipeline = await getFinBERTPipeline();
        modelType = 'finbert';
        break;
      case 'social':
        pipeline = await getTwitterPipeline();
        modelType = 'twitter';
        break;
      default:
        pipeline = await getFastPipeline();
        modelType = 'fast';
    }

    const output = await wrapWithLimiter('huggingface-inference', () => 
      pipeline(text, { truncation: true, max_length: 512 })
    );

    const normalized = normalizeOutput(output, modelType);

    const result: SentimentResult = {
      text: text.slice(0, 200),
      label: normalized.label as any,
      score: normalized.score,
      confidence: normalized.confidence,
      model: modelType,
    };

    cache.set(cacheKey, result, 300000);
    return result;
  } catch (error) {
    console.error('[ML] Sentiment analysis failed:', error);
    return {
      text: text.slice(0, 200),
      label: 'neutral',
      score: 0,
      confidence: 0,
      model: 'error',
    };
  }
}

export async function analyzeBatch(
  texts: { text: string; sourceType: 'news' | 'social' | 'filing' | 'general' }[]
): Promise<SentimentResult[]> {
  // Process in sequence to manage memory
  const results: SentimentResult[] = [];
  
  for (const item of texts) {
    const result = await analyzeSentiment(item.text, item.sourceType);
    results.push(result);
  }
  
  return results;
}

// Aggregate multiple sentiment results
export function aggregateSentiment(results: SentimentResult[]): {
  overallScore: number;
  confidence: number;
  distribution: { positive: number; negative: number; neutral: number };
} {
  if (results.length === 0) {
    return { overallScore: 0, confidence: 0, distribution: { positive: 0, negative: 0, neutral: 0 } };
  }

  const scores = results.map(r => r.score);
  const confidences = results.map(r => r.confidence);
  
  const overallScore = scores.reduce((a, b) => a + b, 0) / scores.length;
  const confidence = confidences.reduce((a, b) => a + b, 0) / confidences.length;
  
  const distribution = {
    positive: results.filter(r => r.label === 'positive').length / results.length,
    negative: results.filter(r => r.label === 'negative').length / results.length,
    neutral: results.filter(r => r.label === 'neutral').length / results.length,
  };

  return { overallScore, confidence, distribution };
}

// Memory management
export function unloadModels(): void {
  finbertPipeline = null;
  twitterSentimentPipeline = null;
  fastSentimentPipeline = null;
  console.log('[ML] Models unloaded');
}
```

---

## PHASE 5: UNIFIED DATA ROUTER

### 5.1 Multi-Provider Market Data Service

**File: `server/services/market-data-router.ts`**

```typescript
import { ProviderFallbackManager, ProviderAdapter, FallbackResult } from '../lib/providerFallback';
import { ApiCache } from '../lib/apiCache';

// Import all connectors
import * as binance from '../connectors/binance';
import * as defillama from '../connectors/defillama';
import * as alphaVantage from '../connectors/alpha-vantage';
import * as secEdgar from '../connectors/sec-edgar';
import * as fred from '../connectors/fred';

// Existing connectors
import * as alpaca from '../connectors/alpaca';
import * as finnhub from '../connectors/finnhub';
import * as coingecko from '../connectors/coingecko';

const cache = new ApiCache(60);

// Normalized quote interface
export interface NormalizedQuote {
  symbol: string;
  price: number;
  change: number;
  changePercent: number;
  volume: number;
  high: number;
  low: number;
  timestamp: Date;
  source: string;
}

// Crypto quote providers (priority order: free first)
const cryptoQuoteProviders: ProviderAdapter<NormalizedQuote>[] = [
  {
    name: 'binance',
    priority: 1,
    costPerCall: 0,
    isEnabled: () => true,
    fetch: async (symbol: string) => {
      const quote = await binance.getCryptoQuote(symbol);
      if (!quote) throw new Error('No quote');
      return {
        symbol: quote.symbol,
        price: quote.price,
        change: quote.change24h,
        changePercent: quote.changePercent24h,
        volume: quote.volume24h,
        high: quote.high24h,
        low: quote.low24h,
        timestamp: quote.timestamp,
        source: 'binance',
      };
    },
  },
  {
    name: 'coingecko',
    priority: 2,
    costPerCall: 0.001,
    isEnabled: () => !!process.env.COINGECKO_API_KEY,
    fetch: async (symbol: string) => {
      const quote = await coingecko.getCryptoPrice(symbol);
      if (!quote) throw new Error('No quote');
      return {
        symbol: symbol.toUpperCase(),
        price: quote.price,
        change: quote.change24h,
        changePercent: quote.changePercent24h,
        volume: quote.volume24h,
        high: quote.high24h,
        low: quote.low24h,
        timestamp: new Date(),
        source: 'coingecko',
      };
    },
  },
];

// Stock quote providers
const stockQuoteProviders: ProviderAdapter<NormalizedQuote>[] = [
  {
    name: 'alpaca',
    priority: 1,
    costPerCall: 0,
    isEnabled: () => !!process.env.ALPACA_API_KEY,
    fetch: async (symbol: string) => {
      const quote = await alpaca.getQuote(symbol);
      if (!quote) throw new Error('No quote');
      return {
        symbol,
        price: quote.price,
        change: quote.change,
        changePercent: quote.changePercent,
        volume: quote.volume,
        high: quote.high,
        low: quote.low,
        timestamp: new Date(),
        source: 'alpaca',
      };
    },
  },
  {
    name: 'finnhub',
    priority: 2,
    costPerCall: 0,
    isEnabled: () => !!process.env.FINNHUB_API_KEY,
    fetch: async (symbol: string) => {
      const quote = await finnhub.getQuote(symbol);
      if (!quote) throw new Error('No quote');
      return {
        symbol,
        price: quote.c,
        change: quote.d,
        changePercent: quote.dp,
        volume: quote.v || 0,
        high: quote.h,
        low: quote.l,
        timestamp: new Date(),
        source: 'finnhub',
      };
    },
  },
];

const cryptoFallbackManager = new ProviderFallbackManager(
  cryptoQuoteProviders,
  cache,
  'crypto-quote',
  15000
);

const stockFallbackManager = new ProviderFallbackManager(
  stockQuoteProviders,
  cache,
  'stock-quote',
  30000
);

export async function getQuote(
  symbol: string,
  assetType: 'stock' | 'crypto'
): Promise<FallbackResult<NormalizedQuote>> {
  const manager = assetType === 'crypto' ? cryptoFallbackManager : stockFallbackManager;
  return manager.fetch(symbol, symbol);
}

export async function getMultipleQuotes(
  symbols: string[],
  assetType: 'stock' | 'crypto'
): Promise<Map<string, NormalizedQuote>> {
  const results = new Map<string, NormalizedQuote>();
  
  // Use batch endpoints where available
  if (assetType === 'crypto') {
    const binanceQuotes = await binance.getMultipleQuotes(symbols);
    for (const [symbol, quote] of binanceQuotes) {
      results.set(symbol, {
        symbol: quote.symbol,
        price: quote.price,
        change: quote.change24h,
        changePercent: quote.changePercent24h,
        volume: quote.volume24h,
        high: quote.high24h,
        low: quote.low24h,
        timestamp: quote.timestamp,
        source: 'binance',
      });
    }
  } else {
    // Stock: fetch individually with fallback
    await Promise.all(
      symbols.map(async (symbol) => {
        try {
          const result = await getQuote(symbol, 'stock');
          results.set(symbol.toUpperCase(), result.data);
        } catch {
          // Skip failed symbols
        }
      })
    );
  }
  
  return results;
}

// Comprehensive data package for AI analysis
export interface MarketDataPackage {
  quote: NormalizedQuote;
  fundamentals?: secEdgar.CompanyFundamentals | alphaVantage.StockOverview;
  recentFilings?: secEdgar.SECFiling[];
  macroContext?: Awaited<ReturnType<typeof fred.getMacroSnapshot>>;
  defiMetrics?: Awaited<ReturnType<typeof defillama.getDeFiSignals>>;
}

export async function getComprehensiveData(
  symbol: string,
  assetType: 'stock' | 'crypto'
): Promise<MarketDataPackage> {
  const [quoteResult, macroContext] = await Promise.all([
    getQuote(symbol, assetType),
    fred.getMacroSnapshot().catch(() => undefined),
  ]);

  const pkg: MarketDataPackage = {
    quote: quoteResult.data,
    macroContext,
  };

  if (assetType === 'stock') {
    const [fundamentals, recentFilings] = await Promise.all([
      secEdgar.getCompanyFacts(symbol).catch(() => 
        alphaVantage.getCompanyOverview(symbol)
      ),
      secEdgar.getRecentFilings(symbol, ['10-K', '10-Q', '8-K'], 5).catch(() => []),
    ]);
    
    pkg.fundamentals = fundamentals || undefined;
    pkg.recentFilings = recentFilings;
  } else {
    pkg.defiMetrics = await defillama.getDeFiSignals().catch(() => undefined);
  }

  return pkg;
}
```

---

## PHASE 6: ADMIN API ENDPOINTS

### 6.1 Provider Status & Control Endpoints

**File: `server/routes/admin-providers.ts`**

```typescript
import { Router } from 'express';
import { getAllProviderStatus, getProviderStatus } from '../lib/rateLimiter';
import { getAllBreakerStats, resetBreaker } from '../lib/circuitBreaker';
import * as alphaVantage from '../connectors/alpha-vantage';

const router = Router();

// GET /api/admin/providers/status
router.get('/status', (req, res) => {
  const rateLimits = getAllProviderStatus();
  const circuitBreakers = getAllBreakerStats();
  const avBudget = alphaVantage.checkBudget();

  res.json({
    providers: {
      rateLimits,
      circuitBreakers,
      budgets: {
        'alpha-vantage': avBudget,
      },
    },
    timestamp: new Date().toISOString(),
  });
});

// GET /api/admin/providers/:provider/status
router.get('/:provider/status', (req, res) => {
  const { provider } = req.params;
  
  res.json({
    provider,
    rateLimit: getProviderStatus(provider),
    circuitBreaker: getAllBreakerStats()[`provider:${provider}`] || null,
  });
});

// POST /api/admin/providers/:provider/reset-breaker
router.post('/:provider/reset-breaker', (req, res) => {
  const { provider } = req.params;
  const success = resetBreaker(`provider:${provider}`);
  
  res.json({
    success,
    message: success 
      ? `Circuit breaker for ${provider} reset` 
      : `No circuit breaker found for ${provider}`,
  });
});

// GET /api/admin/providers/health
router.get('/health', async (req, res) => {
  const health: Record<string, 'healthy' | 'degraded' | 'down'> = {};
  
  const breakers = getAllBreakerStats();
  for (const [name, stats] of Object.entries(breakers)) {
    if (!stats) continue;
    
    const providerName = name.replace('provider:', '');
    if (stats.failures > stats.successes) {
      health[providerName] = 'degraded';
    } else if (stats.rejects > 0) {
      health[providerName] = 'down';
    } else {
      health[providerName] = 'healthy';
    }
  }

  res.json({ health, timestamp: new Date().toISOString() });
});

export default router;
```

---

## PHASE 7: ENVIRONMENT CONFIGURATION

### 7.1 Required Environment Variables

Add these to Replit Secrets:

```bash
# ===== FREE API KEYS (Required) =====
# Get from: https://fred.stlouisfed.org/docs/api/api_key.html
FRED_API_KEY=your_fred_api_key

# Get from: https://www.alphavantage.co/support/#api-key
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key

# Reddit OAuth (free): https://www.reddit.com/prefs/apps
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret
REDDIT_USERNAME=your_reddit_username
REDDIT_PASSWORD=your_reddit_password

# ===== EXISTING KEYS (Keep as-is) =====
ALPACA_API_KEY=existing_key
ALPACA_SECRET_KEY=existing_secret
FINNHUB_API_KEY=existing_key
COINGECKO_API_KEY=existing_key
NEWS_API_KEY=existing_key
OPENAI_API_KEY=existing_key
GROQ_API_KEY=existing_key

# ===== NO KEY REQUIRED =====
# SEC EDGAR - Just needs User-Agent header
# Binance Public API - No auth for market data
# DeFiLlama - Completely free, no auth
# StockTwits - Public endpoints
# yfinance - No auth (unofficial)
```

### 7.2 Package.json Scripts

Add to `package.json`:

```json
{
  "scripts": {
    "preload-models": "node -e \"require('./server/services/ml-sentiment').analyzeSentiment('test', 'general')\"",
    "test:connectors": "tsx server/tests/connector-health.ts",
    "monitor:providers": "tsx server/scripts/provider-monitor.ts"
  }
}
```

---

## PHASE 8: INTEGRATION TEST SUITE

### 8.1 Connector Health Check Script

**File: `server/tests/connector-health.ts`**

```typescript
import * as binance from '../connectors/binance';
import * as defillama from '../connectors/defillama';
import * as secEdgar from '../connectors/sec-edgar';
import * as fred from '../connectors/fred';
import * as alphaVantage from '../connectors/alpha-vantage';
import * as reddit from '../connectors/reddit';
import * as stocktwits from '../connectors/stocktwits';

async function testConnector(name: string, fn: () => Promise<any>): Promise<{
  name: string;
  success: boolean;
  latencyMs: number;
  error?: string;
}> {
  const start = Date.now();
  try {
    await fn();
    return { name, success: true, latencyMs: Date.now() - start };
  } catch (error) {
    return { 
      name, 
      success: false, 
      latencyMs: Date.now() - start,
      error: (error as Error).message,
    };
  }
}

async function runHealthChecks() {
  console.log('Starting connector health checks...\n');

  const results = await Promise.all([
    // Free - No Auth
    testConnector('Binance', () => binance.getCryptoQuote('BTC')),
    testConnector('DeFiLlama', () => defillama.getProtocols()),
    testConnector('SEC EDGAR', () => secEdgar.getCompanyFacts('AAPL')),
    testConnector('StockTwits', () => stocktwits.getSymbolStream('AAPL')),
    
    // Free - With Auth
    testConnector('FRED', () => fred.getLatestValue(fred.FRED_SERIES.FED_FUNDS_RATE)),
    testConnector('Alpha Vantage', () => alphaVantage.getCompanyOverview('AAPL')),
    testConnector('Reddit', () => reddit.getSubredditPosts('wallstreetbets', { limit: 5 })),
  ]);

  console.log('Results:');
  console.log('========');
  
  for (const result of results) {
    const status = result.success ? '' : '';
    const latency = `${result.latencyMs}ms`;
    const error = result.error ? ` - ${result.error}` : '';
    console.log(`${status} ${result.name}: ${latency}${error}`);
  }

  const successCount = results.filter(r => r.success).length;
  console.log(`\n${successCount}/${results.length} connectors healthy`);
  
  process.exit(successCount === results.length ? 0 : 1);
}

runHealthChecks();
```

---

## IMPLEMENTATION CHECKLIST

### Week 1: Core Infrastructure
- [ ] Install all dependencies
- [ ] Create `server/lib/rateLimiter.ts`
- [ ] Create `server/lib/circuitBreaker.ts`  
- [ ] Create `server/lib/providerFallback.ts`
- [ ] Update `server/lib/apiCache.ts` with stale-while-revalidate

### Week 2: Free Data Connectors
- [ ] Create `server/connectors/sec-edgar.ts`
- [ ] Create `server/connectors/fred.ts`
- [ ] Create `server/connectors/binance.ts`
- [ ] Create `server/connectors/defillama.ts`
- [ ] Create `server/connectors/alpha-vantage.ts`

### Week 3: Social Media & Sentiment
- [ ] Create `server/connectors/reddit.ts`
- [ ] Create `server/connectors/stocktwits.ts`
- [ ] Create `server/services/social-sentiment-aggregator.ts`
- [ ] Create `server/services/ml-sentiment.ts`

### Week 4: Integration & Testing
- [ ] Create `server/services/market-data-router.ts`
- [ ] Create `server/routes/admin-providers.ts`
- [ ] Create `server/tests/connector-health.ts`
- [ ] Add environment variables to Replit Secrets
- [ ] Run full integration test suite
- [ ] Update Admin UI with provider status dashboard

---

## COST SUMMARY

| Component | Monthly Cost |
|-----------|--------------|
| Replit Reserved VM (8GB) | $25-40 |
| All data APIs | $0 (free tiers) |
| Reddit API | $0 (free with OAuth) |
| Hugging Face Inference | $0 (local models) |
| **TOTAL** | **$25-40/month** |

---

## SUCCESS METRICS

After implementation, verify:

1. **Reliability**: 99%+ uptime through multi-provider fallback
2. **Cost Reduction**: Zero additional API costs beyond existing subscriptions
3. **Data Coverage**: 
   - Stocks: SEC filings + Alpaca + Finnhub fallback
   - Crypto: Binance + DeFiLlama + CoinGecko fallback
   - Macro: FRED economic indicators
   - Sentiment: Reddit + StockTwits + ML models
4. **Latency**: <500ms p95 for quote fetches
5. **Rate Limit Compliance**: Zero 429 errors through proper throttling